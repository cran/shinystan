<div class = "glossary-entry">
<h3>HMC and NUTS (very briefly)</h3>

This is a very brief overview. For more details see the Stan manual and 
<a href="https://arxiv.org/abs/1701.02434"> Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo.</a>


<h4>Hamiltonian Monte Carlo</h4>
Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) method that
uses the derivatives of the density function being sampled to generate
efficient transitions spanning the posterior. It uses an approximate Hamiltonian 
dynamics simulation based on numerical integration which is then corrected by 
performing a Metropolis acceptance step.

<br><br>
<span class="help-block"> <em>Algorithm summary</em> </span>

The Hamiltonian Monte Carlo algorithm starts at a specified initial set of
parameters; in Stan, this value is either user-specified or generated
randomly. Then, for a given number of iterations, a new momentum vector is
sampled and the current value of the parameters is updated using the leapfrog
integrator with discretization time <code>stepsize</code> and number of 
steps <code>n_leapfrog</code> according to the Hamiltonian dynamics. 
Then a Metropolis acceptance step is applied, and a decision is made whether 
to update to the new state or keep the existing state.


<h4 style="margin-top: 20px;">No-U-Turn Sampler</h4>

The no-U-turn sampler (NUTS) automatically selects an appropriate 
<code>n_leapfrog</code> in each iteration in order to allow the 
proposals to traverse the posterior without doing unnecessary work. 
The motivation is to maximize the expected squared jump distance 
(see, e.g., 
Roberts et al. (<a href = "http://www.jstor.org/stable/2245134">1997</a>)) 
at each step and avoid the random-walk behavior that arises in random-walk 
Metropolis or Gibbs samplers when there is correlation in the posterior. 
For a precise definition of the NUTS algorithm see Hoffman and Gelman 
(<a href = "http://arxiv.org/abs/1111.4246">2011</a>, 
<a href = "http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf">2014</a>)

<br><br>
<span class="help-block"> <em>Algorithm summary</em> </span>

NUTS generates a proposal by starting at an initial position determined 
by the parameters drawn in the last iteration. It then generates an independent 
unit-normal random momentum vector. It then evolves the initial system both 
forwards and backwards in time to form a balanced binary tree. At each iteration 
of the NUTS algorithm the <code>treedepth</code> is increased by one, doubling 
<code>n_leapfrog</code> and effectively doubling the computation time. 
The algorithm terminates in one of two ways, either

<ul>
  <li>the NUTS criterion (i.e., a U-turn in Euclidean space on a subtree) 
  is satisfied for a new subtree or the completed tree, or</li>
  <li>the depth of the completed tree hits the maximum depth allowed.</li>
</ul>
 
Rather than using a standard Metropolis step, the final parameter value 
is selected via multinomial sampling among the Hamiltonian trajectories.

<br><br>
Configuring the no-U-turn sampler involves putting a cap on the <code>treedepth</code>
that it evaluates during each iteration. This is controlled through a maximum depth parameter. The number of leapfrog steps taken is then bounded by 2 to the power 
of the maximum depth minus 1.
<br><br>

<p>
For more details see 
<a href="https://arxiv.org/abs/1701.02434"> Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo.</a>
</p>

</div>