<div class = "glossary-entry">
<h3>divergent</h3>

<span class="help-block" style = "margin-top: 15px;">
  <em>Quick definition</em>
</span>
  
The number of leapfrog transitions with diverging error. Because NUTS terminates 
at the first divergence this will be either 0 or 1 for each iteration. 
The average value of <code>divergent</code> over all iterations is therefore 
the proportion of iterations with diverging error.

<br><br>
<h4>More details</h4>

<p>
When numerical issues arise during the evaluation of the parameter
Jacobians or the model log density, an exception is raised in the
underlying code and the current expansion of the Hamiltonian forward
and backward in time is halted. This is marked as a divergent
transition.
</p>

<p>
The primary cause of divergent transitions in Euclidean HMC (other
than bugs in the model code) is numerical instability in the leapfrog
integrator used to simulate the Hamiltonian evaluation. The
fundamental problem is that a fixed step size is being multiplied by
the gradient at a particular point, to determine the next simulated
point. If the stepsize is too large, this can overshoot into
ill-defined portions of the posterior.  
</p>

<p>
<strong>
If there are (post-warmup) divergences then the results may be biased and 
should not be used.
</strong>
</p>

<p>
In some cases, simply lowering the initial step size and increasing
the target acceptance rate will keep the step size small enough that
sampling can proceed.  
</p>

<p>
The exact cause of each divergent transition is printed as a warning 
message in the output console. This can be useful in cases where managing 
the step size is insufficient.  In such cases, a reparameterization is 
often required so that the posterior curvature is more manageable; 
see the section about Neal's Funnel in the Stan manual for an example.
</p>

For more details see 
<a href="https://arxiv.org/abs/1701.02434"> Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo.</a>
</div>
